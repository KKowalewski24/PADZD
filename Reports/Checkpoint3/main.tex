\documentclass{classrep}
\usepackage[utf8]{inputenc}
\frenchspacing

\usepackage{graphicx}
\usepackage[usenames,dvipsnames]{color}
\usepackage[hidelinks]{hyperref}
\usepackage{lmodern}
\usepackage{graphicx}
\usepackage{placeins}
\usepackage{url}
\usepackage{amsmath, amssymb, mathtools}
\usepackage{listings}
\usepackage{fancyhdr, lastpage}

\pagestyle{fancyplain}
\fancyhf{}
\renewcommand{\headrulewidth}{0pt}
\cfoot{\thepage\ / \pageref*{LastPage}}

%--------------------------------------------------------------------------------------%
\studycycle{Informatyka stosowana, studia dzienne, II st.}
\coursesemester{II}

\coursename{Przetwarzanie i analiza dużych zbiorów danych}
\courseyear{2021/2022}

\courseteacher{mgr inż. Rafał Woźniak}
\coursegroup{Czwartek, 15:45}

\author{%
    \studentinfo[239661@edu.p.lodz.pl]{Szymon Gruda}{239661}\\
    \studentinfo[239671@edu.p.lodz.pl]{Jan Karwowski}{239671}\\
    \studentinfo[239673@edu.p.lodz.pl]{Michał Kidawa}{239673}\\
    \studentinfo[239676@edu.p.lodz.pl]{Kamil Kowalewski}{239676}\\
}

\title{Checkpoint 3}

\begin{document}
    \maketitle
    \thispagestyle{fancyplain}

    \tableofcontents
    \newpage

    \section{Wprowadzenie} \label{intro} {
        Głównym celem projektu jest przeprowadzenie kompleksowej analizy zbioru
        \textit{NYPD Complaint Data Historic} \cite{nypd_dataset}. Jego dokładny opis
        został wykonany w ramach Checkpoint 1 więc w sekcji \ref{dataset_description}
        jest on przedstawiony w dużo bardziej zwięzły sposób. Cele projektu pod
        dokonaniu modyfikacji zgodnie z uwagami z Checkpoint 1 oraz rewizji na
        podstawie wyników uzyskanych w Checkpoint 2 zostały przedstawione w sekcji
        \ref{project_goals}.
    }

    \section{Podział obowiązków w zespole} {
        \begin{itemize}
            \item Szymon Gruda - Kontynuacja prac nad celem, związanym z klasyfikacją kodu przestępstwa.
            \item Jan Karwowski - Badanie sensowności dodanie OneHotEncoding oraz OrdinalEncoding,
            rozwiązywanie problemów z przepełnianiem się pamięci RAM po dokonaniu encodingu
            \item Michał Kidawa - kontynuacja badania eksperymentów związanych z grupowaniem elementów
            zbioru na podstawie istniejących oraz tworzonych cech
            \item Kamil Kowalewski - Zmiany w preprocessingu aby była możliwość osiągnięcia lepszy efektów
            niż te uzyskane w celach w Checkpoint 2 oraz przygotowania sprawozdania
        \end{itemize}
    }

    \section{Charakterystyka zbioru danych} \label{dataset_description} {
        Kolumny w zbiorze danych zdecydowaliśmy się podzielić na następujące grupy:
        \begin{enumerate}
            \item Identyfikator
            \item Data i czas zdarzenia
            \item Data i czas zgłoszenia
            \item Typ i opis wykroczenia/przestępstwa
            \item Czy się udało
            \item Otoczenie zdarzenia
            \item Lokalizacja zdarzenia
            \item Cechy podejrzanego
            \item Cechy ofiary
        \end{enumerate}
    }

    \section{Cele projektu} \label{project_goals} {
        W ramach projektu sformułowane zostały trzy następujące cele.

        \subsection{Klasyfikacja rodzaju lub poziomu przestępstwa}
        \label{project_goal_1} {

            W ramach tego etapu przeprowadzony zostanie szereg eksperymentów mających
            na celu stworzenie klasyfikatora typu przestępstwa (KY\_CD). Jeżeli okaże
            się to niemożliwe podjęta zostanie próba klasyfikacji poziomu wykroczenia,
            stanowiącego bardziej ogólną informacje. Klasyfikacja ta będzie odbywała
            się na podstawie następujących informacji:
            \begin{itemize}
                \item godzina zdarzenia
                \item dzień tygodnia zdarzenia
                \item odstęp między zgłoszeniem a zdarzeniem
                \item czy doszło do skutku (CRM\_ATPT\_CPTD\_CD)
                \item otoczenie zdarzenia
                \item cechy podejrzanego
                \item cechy ofiary
                \item poziom lub typ przestępstwa w zależności od tego co klasyfikujemy
            \end{itemize}

            Wybrane cechy mogą ulec drobnym modyfikacjom w trakcie trwania
            eksperymentów. Opcjonalnie podjęta będzie próba wykorzystania informacji o
            czasie trwania przestępstwa (dla tych zdarzeń, dla których jest dostępna).

            Informacja o dokładnej lokalizacji zdarzenia nie jest wykorzystana ze
            względu na chęć stworzenia uniwersalnego narzędzia.

            Aby zrealizować zaproponowany cel wykorzystane zostaną następujące metody:
            metody imputacji brakujących danych, prosta ekstrakcja cech (zwłaszcza z
            daty), naiwny klasyfikator Bayesa i lasy losowe.
        }

        \subsection{Regresja czasu trwania przestępstwa}
        \label{project_goal_2} {
            Drugim celem będzie regresja czasu trwania przestępstwa dla tych
            przestępstw, dla których jest on znany. Tak więc wybrany zostanie podzbiór
            głównego zbioru danych i na podstawie czasu rozpoczęcia i zakończenia
            przestępstwa wyekstrahowany zostanie czas jego trwania. Na podstawie
            pozostałych kolumn (poza tych z datą i czasem) podjęta będzie próba
            wyuczenia modelu regresyjnego estymowania tego czasu.

            Wykorzystane zostaną modele przystosowane do zadań regresji, tak więc
            przede wszystkim lasy losowe, ewentualnie klasyfikator liniowy, maszyny
            wektorów nośnych czy wreszcie sieć neuronowa. Wykorzystane metody będą
            dobierane odpowiednio w zależności od wyników otrzymywanych w trakcie
            trwania eksperymentów i od napotkanych problemów. Dodatkowo planowane jest
            wykorzystanie biblioteki \emph{XGBoost}.
        }

        \subsection{Grupowanie przestępstw na podstawie podzbiorów cech}
        \label{project_goal_3} {
            W ramach tego celu przeprowadzone zostanie automatyczne grupowanie zdarzeń.
            Spośród cech podejrzanego i ofiary kilkakrotnie wybrany zostanie podzbiorów
            stanowiących przedmiot eksperymentu - etykietę. Dla każdej wybranej
            etykiety (która może być złożeniem kilku atrybutów) przeprowadzona zostanie
            seria eksperymentów, mająca na celu automatyczne pogrupowanie zdarzeń
            zgodnie z tą etykietą, wykorzystując wszystkie pozostałe atrybuty (poza
            tworzącymi etykietę). Po przeprowadzeniu grupowania z wykorzystaniem kilku
            różnych algorytmów (DBSCAN, k-means, algorytm aglomeracyjny), zmierzona
            zostanie jakość grupowania za pomocą metryk zewnętrznych (accuracy)
            względem wybranej etykiety. Dodatkowo porównana zostanie jakość grupowania
            między seriami eksperymentów (dla różnych etykiet) za pomocą metryk
            wewnętrznych.
        }

    }

    \section{Schemat operacji związanych z przetwarzaniem i analizą danych}
    \label{operation_schema} {

        \subsection{Cel 1 - Klasyfikacja} {
            Na podstawie niskiej dokładności klasyfikacji, wykorzystującej naiwny
            klasyfikator Bayes'a, zrezygnowano z dalszego testowania wykorzystania tego
            klasyfikatora, z powodu braku przesłanego, jakoby mógł spełniać swoje
            zadanie, bazując na danych z badanego zbioru danych.
            W celu poprawy rezultatów otrzymywanych na skutek działania klasyfikatora,
            poprawiono kodowanie wartości takich kolumn danych jak płeć, grupa wiekowa,
            dzień tygodnia i dzień roku. Następnie przeprowadzono serię eksperymentów,
            które pozwoliły określić czy cel w obecnej postaci jest możliwy do
            zrealizowania.
        }

    }

    \section{Wstępne przetwarzanie danych} {
        W ramach wstępnego przetwarzania danych został przygotowany skrypt o nazwie
        \textit{dataset\_preprocessing.py}. Jego dokładne działanie zostało opisane w
        ramach Checkpoint 2 w sekcji o tej samej nazwie. Co więcej w ramach Checkpoint
        3 zostały dokonane następujące zmiany aby dane były lepiej przygotowane do
        poszczególnych celów:
        \begin{enumerate}
            \item Konwersja Pandas Datetime na Timestamp aby były to liczby
            \item Dodanie enkodowania kolumn z użyciem OneHotEncoder dla kolumn typu \emph{categorical} -
            dzięki temu powstaję wiele nowych kolumn
            \item Dodanie enkodowania kolumn z użyciem OrdinalEncoder dla kolumn typu \emph{ordinal}
            \item Zapis otrzymanego pliku po dokonaniu enkodowania wskazanymi wyżej metodami oraz dwukrotne
            wykorzystanie PCA na uzyskanym DataFrame z parametrem \emph{n\_components} równym liczbie
            kolumn oraz dwukrotności po pierwszej fazie preprocessingu tzn przed dokonaniem
            enkodowania. Wszystkie trzy pliki były dostępne do użycia w algorytmach i metodach Data
            Science do zrealizowania celów.
        \end{enumerate}
        Po wykonaniu w/w skryptu okazała się niestety, że z powodu tego powstałej
        liczby kolumn nie jest możliwe przeprowadzanie analizy danych na całym pliku.
        Były dokonywane próby optymalizacji tego poprzez dokonanie encodingu w czasie
        działania programu bez tworzenia tak ogromnego pliku natomiast żaden z członków
        grupy nie dysponuję tak potężnym sprzętem, który miałby 40GiB RAMu. Problem ten
        zostanie omówiony z prowadzącym zajęcia w czasie przedstawiania tego
        Checkpointu celem otrzymania sugestii jak go rozwiązać. Dokonane różne warianty
        preprocessingu miały na celu polepszyć wyniki z Checkpoint 2 lecz niestety z
        przyczyn technicznych nie udało się tego dokonać.
    }

    \section{Przetwarzanie i analiza danych} {

        \subsection{Cel 1 - Klasyfikacja} {
            W ramach tego celu zmieniono kodowanie kolumn, przechowujących informację o rasie, płci, grupie
            wiekowej. Zarówno dla podejrzanego jak i dla ofiary przestępstwa. Następnie zakodowano status
            popełnionego przestępstwa. Z analizy danych przeprowadzonych w ramach Checkpoint'u 1, można
            było wnioskować, że dzień tygodnia oraz dzień roku (w kontekście pory roku) może przenosić
            ważne dla klasyfikacji informacje. Dlatego, aby zminimalizować straty informacji, związane z
            wykorzystaniem daty popełnienia przestępstwa. Dzień tygodnia oraz dzień roku, zakodowano jako
            parę wartości funkcji trygonometrycznych sinus i cosinus, dzięki czemu udaje się przechować
            informację o cyklicznej naturze czasu.
            Po przeprowadzeniu tych operacji przeprowadzono naukę oraz test klasyfikatora, wykorzystując do
            tego jeden milion próbek ze zbioru.
            \FloatBarrier

            \begin{table}
                \centering
                \begin{tabular}{|c|c|c|c|}
                    \hline
                    Nazwa parametru & Wartość parametru & Skuteczność trening & skuteczność test \\ \hline
                    min\_samples\_leaf & 10 & 0.7065 & 0.6067 \\ \hline
                    min\_samples\_leaf & 100 & 0.6468 & 0.6342 \\ \hline
                    min\_samples\_leaf & 1000 & 0.6214 & 0.6183 \\ \hline
                    min\_samples\_leaf & 10000 & 0.5909 & 0.5909 \\ \hline
                    max\_depth & 5 & 0.6006 & 0.6002 \\ \hline
                    max\_depth & 10 & 0.6287 & 0.6248 \\ \hline
                    max\_depth & 15 & 0.6673 & 0.6311 \\ \hline
                    max\_depth & 25 & 0.8303 & 0.5875 \\ \hline
                    n\_estimators & 100 & 0.6333 & 0.6287 \\ \hline
                    n\_estimators & 1000 & 0.6343 & 0.6297 \\ \hline

                    max\_samples & 0.01 & 0.5375 & 0.5370 \\ \hline
                    max\_samples & 0.02 & 0.5697 & 0.5697 \\ \hline
                    max\_samples & 0.05 & 0.6034 & 0.6030 \\ \hline
                    max\_samples & 0.1 & 0.6162 & 0.6151 \\ \hline
                    max\_samples & 0.2 & 0.6213 & 0.6194 \\ \hline
                    max\_samples & 0.5 & 0.6295 & 0.6261 \\ \hline
                    max\_samples & 0.8 & 0.6327 & 0.6284 \\ \hline
                    max\_samples & 0.99 & 0.6344 & 0.6299 \\ \hline

                    \hline
                \end{tabular}
                \caption{Wyniki dla lasu losowego przy wykorzystaniu różnych parametrów, dla kodu
                przestępstwa}
                \label{tab:forest_parameters_keyCode}
            \end{table}
            \FloatBarrier

            Następnym krokiem było wybranie najlepszych parametrów i zbadanie dla nich kilku metryk, dla
            dokładności klasyfikacji 62,86\% wartości \textit{Sensitivities} dla kodów przestępstw,
            prezentowały się tak:
            [0. 0.12 0.3734 0.5475 0.2113 0.7401 0. 0. 0. 0.
            0. 0. 0.0389 0.9363 0.0721 0. 0.0574 0. 0. 0.
            0.465 0. 0. 0. 0.0599 0.9807 0. 0. 0. 0.
            0.822 0. 0. 0.9061 0. 0. 0. 0. 0. 0.1015
            0. 0. 0. 0. 0. 0. 0.0098 0. 0.1207 0.
            0. 0. 0. 0. 0.9989 0. 0. 0.    ]

            Natomiast wartości \textit{Precisions}
            [0. 0.4049 0.4818 0.4048 0.4834 0.4861 0. 0. 0. 0.
            0. 0. 0.641 0.3771 0.4219 0. 0.4795 0. 0. 0.
            0.3985 0. 0. 0. 0.6766 0.4683 0. 0. 0. 0.
            0.7215 0. 0. 0.4829 0. 0. 0. 0. 0. 0.6505
            0. 0. 0. 0. 0. 0. 0.9167 0. 0.472 0.
            0. 0. 0. 0. 0.9954 0. 0. 0.    ]


            Po zapoznaniu się z powyższymi wynikami oraz tabelą \ref{tab:forest_parameters_keyCode} można
            stwierdzić, że poczynione zmiany w celu poprawy dokładności klasyfikacji kodu przestępstwa nie
            zaskutkowały wielkimi zmianami. Jest to spowodowane najprawdopobniej niemożliwością wykonania
            takiej klasyfikacji bazując na tych danych. Dlatego zbadane zostało jak zachowuje się
            klasyfikator, przy klasyfikacji poziomu przestępstwa, wyniki eksperymentów zaprezentowano poniżej,


            \begin{table}
                \centering
                \begin{tabular}{|c|c|c|c|}
                    \hline
                    Nazwa parametru & Wartość parametru & Skuteczność trening & skuteczność test \\ \hline
                    min\_samples\_leaf & 10 & 0.9999 & 0.9999 \\ \hline
                    min\_samples\_leaf & 100 & 0.9999 & 0.9999 \\ \hline
                    min\_samples\_leaf & 1000 & 0.9999 & 0.9999 \\ \hline
                    min\_samples\_leaf & 10000 & 0.9999 & 0.9999 \\ \hline
                    max\_depth & 5 & 0.9999 & 0.9999 \\ \hline
                    max\_depth & 10 & 0.9999 & 0.9999 \\ \hline
                    max\_depth & 15 & 0.9999 & 0.9999 \\ \hline
                    max\_depth & 25 & 0.9999 & 0.9999 \\ \hline
                    n\_estimators & 100 & 0.6333 & 0.6287 \\ \hline
                    n\_estimators & 1000 & 0.6343 & 0.6297 \\ \hline

                    max\_samples & 0.01 & 0.9999 & 0.9999 \\ \hline
                    max\_samples & 0.02 & 0.9999 & 0.9999 \\ \hline
                    max\_samples & 0.05 & 0.9967 & 0.9968 \\ \hline
                    max\_samples & 0.1 & 0.9991 & 0.9989 \\ \hline
                    max\_samples & 0.2 & 0.9999 & 0.9999 \\ \hline
                    max\_samples & 0.5 & 0.9999 & 0.9999 \\ \hline
                    max\_samples & 0.8 & 0.9999 & 0.9999 \\ \hline
                    max\_samples & 0.99 & 0.9999 & 0.9999 \\ \hline

                    \hline
                \end{tabular}
                \caption{Wyniki dla lasu losowego przy wykorzystaniu różnych parametrów, dla poziomu
                przestępstwa}
                \label{tab:forest_parameters_law_breaking_law}
            \end{table}
            \FloatBarrier


            Dla najlepszych parametrów zbadano metryki, dla dokładności klasyfikacji 99,99\% wartości
            \textit{Sensitivities} dla kodów przestępstw, prezentowały się tak:
            [0.9999 1. 0.9999]

            Natomiast wartości \textit{Precisions} [0.9999 0.9999 1.    ]
        }

        Macierz pomyłek (ang. \textit{Confusion Matrix}) została zaprezentowana w tabeli
        \ref{tab:forest_forest_confusion_matrix_law_breaking_law}, niestety dla kodu przestępstwa nie udało
        się takiej macierzy przedstawić w sposób czytelny, dlatego pominięto ją w sprawozdaniu.
        \begin{table}[!htbp]
            \centering
            \begin{tabular}{|c|c|c|}
                \hline
                VIOLATION & MISDEMEANOR & FELONY\\ \hline
                35959 & 2 & 0 \\ \hline
                3 & 84691 & 1 \\ \hline
                0 & 3 & 46626 \\ \hline
            \end{tabular}
            \caption
            {Macierz pomyłek dla rodzaju przestępstwa}
            \label{tab:forest_forest_confusion_matrix_law_breaking_law}
        \end{table}
        \FloatBarrier
        Wnioskując na podstawie rozbieżności pomiędzy dokładnościami klasyfikatorów, klasyfikujących kod
        przestępstwa a jego rodzaj można wywnioskować, że jeden cel jest zbyt ambitny, a drugi ma potencjał
        na uogólnienie. Dlatego w kolejnej iteracji badawczej, spróbujemy osiągnąć pewną modyfikację celu i
        wyznaczyć mniejszy zbiór kolumn (lub mniej oczywisty ich dobór), który pozwoli klasyfikować rodzaj
        popełnionego przestępstwa z zachowaniem możliwie największej dokładności klasyfikacji.

        \subsection{Cel 2 - Klasteryzacja} {
            Pomimo zmian zarówno w parametrach klasteryzacji, jak i charakterystyce zbioru, który po
            preprocessingu trafił do metod związanych z grupowanie nie udało się poprawić jakości
            klasteryzacji. Przy zmianie liczby klastrów otrzymywane wyniki grupowania nadal stanowiły trend
            podziału danych na 1 / N, gdzie N to liczba klastrów. Algorytm DBSCAN nadal klasyfikował
            wszystkie próbki jako elementy wyjątkowe, czyli outliers.
        }

    }

    \begin{thebibliography}{0}
        % @formatter:off
        \bibitem{nypd_dataset}{https://data.cityofnewyork.us/Public-Safety/NYPD-Complaint-Data-Historic/qgea-i56i}
        % @formatter:on
    \end{thebibliography}

\end{document}
